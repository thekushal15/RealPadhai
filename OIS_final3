import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.decomposition import PCA
import shap

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

import optuna

# Set seed for reproducibility
torch.manual_seed(42)
np.random.seed(42)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class YieldLSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.2):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, num_layers=2, dropout=dropout, bidirectional=True)
        self.fc = nn.Sequential(
            nn.Linear(hidden_dim * 2, 128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, output_dim)
        )

    def forward(self, x):
        self.train()  # Always enable dropout (MC Dropout)
        out, _ = self.lstm(x)
        out = out[:, -1, :]
        return self.fc(out)

def create_sequences(df, input_cols, target_cols, window=7):
    X_seq, y_seq, D_seq = [], [], []
    for i in range(len(df) - window):
        X_seq.append(df[input_cols].iloc[i:i+window].values)
        y_seq.append(df[target_cols].iloc[i+window].values)
        D_seq.append(df['Dates'].iloc[i+window])
    return np.array(X_seq), np.array(y_seq), np.array(D_seq)

def train_model(model, train_loader, val_loader, optimizer, loss_fn, device, max_epochs=50, patience=5):
    train_losses, val_losses = [], []
    best_model, best_val_loss = None, float('inf')
    wait = 0

    for epoch in range(max_epochs):
        model.train()
        train_loss = 0
        for xb, yb in train_loader:
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            preds = model(xb)
            loss = loss_fn(preds, yb)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        train_losses.append(train_loss)

        model.eval()
        val_loss = 0
        with torch.no_grad():
            for xb, yb in val_loader:
                xb, yb = xb.to(device), yb.to(device)
                preds = model(xb)
                val_loss += loss_fn(preds, yb).item()
        val_losses.append(val_loss)

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model = model.state_dict()
            wait = 0
        else:
            wait += 1
            if wait >= patience:
                break

    model.load_state_dict(best_model)

    plt.plot(train_losses, label="Train Loss")
    plt.plot(val_losses, label="Val Loss")
    plt.title("Loss Curve")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.show()

    return model

def objective(trial):
    hidden_dim = trial.suggest_int("hidden_dim", 32, 128)
    dropout = trial.suggest_float("dropout", 0.1, 0.5)
    lr = trial.suggest_float("lr", 1e-4, 1e-2, log=True)

    model = YieldLSTM(input_dim=X_seq.shape[2], hidden_dim=hidden_dim, output_dim=len(target_cols), dropout=dropout).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    loss_fn = nn.MSELoss()
    model = train_model(model, train_loader, val_loader, optimizer, loss_fn, device)

    model.eval()
    with torch.no_grad():
        X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)
        y_val_pred_scaled = model(X_val_tensor).cpu().numpy()

    y_val_pred = scaler_y.inverse_transform(y_val_pred_scaled)
    y_val_true_ = scaler_y.inverse_transform(y_val)

    return -r2_score(y_val_true_, y_val_pred)

def fit_best_model(best_params):
    model = YieldLSTM(
        input_dim=X_seq.shape[2],
        hidden_dim=best_params['hidden_dim'],
        output_dim=len(target_cols),
        dropout=best_params['dropout']
    ).to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=best_params['lr'])
    loss_fn = nn.MSELoss()
    model = train_model(model, train_loader, val_loader, optimizer, loss_fn, device)
    return model

def plot_predictions(dates, y_true, y_pred, tenors):
    for i, tenor in enumerate(tenors):
        plt.figure(figsize=(10, 4))
        plt.plot(dates, y_true[:, i], label='Actual')
        plt.plot(dates, y_pred[:, i], '--', label='Predicted')
        plt.title(f"Yield: {tenor}")
        plt.xlabel("Date")
        plt.ylabel("Yield")
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()

def plot_yield_curves(y_true, y_pred, tenors):
    for i in range(0, len(y_pred), max(1, len(y_pred)//5)):
        plt.plot(tenors, y_true[i], label=f"True {i}")
        plt.plot(tenors, y_pred[i], '--', label=f"Pred {i}")
    plt.title("Yield Curve Shapes")
    plt.xlabel("Tenor")
    plt.ylabel("Yield")
    plt.legend()
    plt.grid(True)
    plt.show()

def predict_with_uncertainty(model, input_tensor, scaler_y, target_cols, n_samples=30):
    model.eval()
    preds = []
    for _ in range(n_samples):
        with torch.no_grad():
            pred = model(input_tensor).cpu().numpy()
            preds.append(pred)

    preds = np.array(preds).squeeze()
    mean_pred = preds.mean(axis=0)
    std_pred = preds.std(axis=0)

    lower = scaler_y.inverse_transform([mean_pred - 1.96 * std_pred])[0]
    upper = scaler_y.inverse_transform([mean_pred + 1.96 * std_pred])[0]
    mean = scaler_y.inverse_transform([mean_pred])[0]

    plt.plot(target_cols, mean, label='Prediction', marker='o')
    plt.fill_between(target_cols, lower, upper, alpha=0.3, label='95% CI')
    plt.title("Predicted Yield Curve with Uncertainty")
    plt.ylabel("Yield")
    plt.xlabel("Tenor")
    plt.grid(True)
    plt.legend()
    plt.show()

    return mean, lower, upper

def shap_summary_plot(X_input, model, background_size=100):
    background = torch.tensor(X_input[np.random.choice(X_input.shape[0], background_size)], dtype=torch.float32)
    explainer = shap.DeepExplainer(model, background)
    shap_values = explainer.shap_values(torch.tensor(X_input[:background_size], dtype=torch.float32))
    shap.summary_plot(shap_values, X_input[:background_size])






study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=20)
print(study.best_trial.params)


best_model = fit_best_model(study.best_trial.params)



best_model.eval()
with torch.no_grad():
    y_val_pred_scaled = best_model(torch.tensor(X_val, dtype=torch.float32).to(device)).cpu().numpy()
    y_val_pred = scaler_y.inverse_transform(y_val_pred_scaled)

r2_val = r2_score(scaler_y.inverse_transform(y_val), y_val_pred)
print("RÂ² on Validation:", r2_val)

plot_predictions(D_val, scaler_y.inverse_transform(y_val), y_val_pred, target_cols)



shap_summary_plot(X_seq.reshape(X_seq.shape[0], -1), best_model)
