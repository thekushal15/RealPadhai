import pandas as pd
import itertools
import numpy as np

# List of bond tenors based on provided columns
tenors = ['26', '30', '31', '32', '35', '36', '37', '40', '41']

# Generate all possible pairs
pairs = list(itertools.combinations(tenors, 2))

# Initialize columns
def initialize_columns(df, tenors, pairs):
    for tenor in tenors:
        df[f'Pos_{tenor}'] = 0.0
    df['Borrowed'] = 0.0
    for pair in pairs:
        pair_key = f"{pair[0]}_{pair[1]}"
        df[f'PnL_{pair_key}'] = 0.0
    df['Total_PnL'] = 0.0
    df['Cumulative_PnL'] = 0.0
    return df

# Trading strategy logic
def apply_trading_strategy(df, tenors, pairs, pair_stop_loss=-1_000, daily_stop_loss=-10_000):
    df = initialize_columns(df, tenors, pairs)
    
    position_state = {f"{pair[0]}_{pair[1]}": False for pair in pairs}
    entry_price = {}
    pair_positions = {}
    running_pnl = {f"{pair[0]}_{pair[1]}": 0.0 for pair in pairs}
    prev_z = {f"{pair[0]}_{pair[1]}": None for pair in pairs}  # Track previous z-score
    
    for i in range(len(df)):
        row = df.iloc[i]
        daily_pnl = 0.0  # Track daily PnL for portfolio stop-loss
        
        for pair in pairs:
            short_tenor, long_tenor = pair
            pair_key = f"{short_tenor}_{long_tenor}"
            z = row[(f'{short_tenor}_Yld', f'{long_tenor}_Yld')]
            
            # Check for large z-score change to avoid volatile entries
            if i > 0 and prev_z[pair_key] is not None:
                z_change = abs(z - prev_z[pair_key])
                if z_change > 3:  # Skip entry if z-score jumps too much
                    prev_z[pair_key] = z
                    continue
            
            if not position_state[pair_key]:
                if z >= 2:  # Spread too wide, expect it to narrow
                    scale = row[f'{long_tenor}_Dv01'] / row[f'{short_tenor}_Dv01']
                    notional = 1_000_000 / (row[f'{long_tenor}_Dv01'] + scale * row[f'{short_tenor}_Dv01'])
                    pos_short = -notional * scale
                    pos_long = notional
                    df.iloc[i, df.columns.get_loc(f'Pos_{short_tenor}')] += pos_short
                    df.iloc[i, df.columns.get_loc(f'Pos_{long_tenor}')] += pos_long
                    df.iloc[i, df.columns.get_loc('Borrowed')] += 1_000_000
                    entry_price[pair_key] = (row[f'{short_tenor}_Px'], row[f'{long_tenor}_Px'])
                    pair_positions[pair_key] = (pos_short, pos_long)
                    position_state[pair_key] = True
                    running_pnl[pair_key] = 0.0
                elif z <= -2:  # Spread too narrow, expect it to widen
                    scale = row[f'{long_tenor}_Dv01'] / row[f'{short_tenor}_Dv01']
                    notional = 1_000_000 / (row[f'{long_tenor}_Dv01'] + scale * row[f'{short_tenor}_Dv01'])
                    pos_short = notional * scale
                    pos_long = -notional
                    df.iloc[i, df.columns.get_loc(f'Pos_{short_tenor}')] += pos_short
                    df.iloc[i, df.columns.get_loc(f'Pos_{long_tenor}')] += pos_long
                    df.iloc[i, df.columns.get_loc('Borrowed')] += 1_000_000
                    entry_price[pair_key] = (row[f'{short_tenor}_Px'], row[f'{long_tenor}_Px'])
                    pair_positions[pair_key] = (pos_short, pos_long)
                    position_state[pair_key] = True
                    running_pnl[pair_key] = 0.0
            else:
                if i > 0:
                    current_price = (row[f'{short_tenor}_Px'], row[f'{long_tenor}_Px'])
                    pos_short, pos_long = pair_positions[pair_key]
                    unrealized_pnl = (current_price[0] - entry_price[pair_key][0]) * pos_short + \
                                     (current_price[1] - entry_price[pair_key][1]) * pos_long
                    
                    # Cap loss at pair_stop_loss
                    if unrealized_pnl <= pair_stop_loss:
                        # Assume exit at price causing exactly pair_stop_loss
                        pnl = pair_stop_loss
                    else:
                        pnl = unrealized_pnl
                    running_pnl[pair_key] = pnl
                
                if abs(z) <= 0.75 or running_pnl[pair_key] <= pair_stop_loss:
                    exit_price = (row[f'{short_tenor}_Px'], row[f'{long_tenor}_Px'])
                    pos_short, pos_long = pair_positions[pair_key]
                    if running_pnl[pair_key] <= pair_stop_loss:
                        pnl = pair_stop_loss  # Enforce stop-loss cap
                    else:
                        pnl = (exit_price[0] - entry_price[pair_key][0]) * pos_short + \
                              (exit_price[1] - entry_price[pair_key][1]) * pos_long
                    df.iloc[i, df.columns.get_loc(f'PnL_{pair_key}')] = pnl
                    df.iloc[i, df.columns.get_loc(f'Pos_{short_tenor}')] -= pos_short
                    df.iloc[i, df.columns.get_loc(f'Pos_{long_tenor}')] -= pos_long
                    position_state[pair_key] = False
                    running_pnl[pair_key] = 0.0
                    pair_positions.pop(pair_key, None)
            
            daily_pnl += df.iloc[i][f'PnL_{pair_key}']
            prev_z[pair_key] = z
        
        # Portfolio-level stop-loss
        if daily_pnl <= daily_stop_loss:
            # Close all open positions
            for pair in pairs:
                pair_key = f"{pair[0]}_{pair[1]}"
                if position_state[pair_key]:
                    short_tenor, long_tenor = pair
                    pos_short, pos_long = pair_positions[pair_key]
                    df.iloc[i, df.columns.get_loc(f'Pos_{short_tenor}')] -= pos_short
                    df.iloc[i, df.columns.get_loc(f'Pos_{long_tenor}')] -= pos_long
                    position_state[pair_key] = False
                    running_pnl[pair_key] = 0.0
                    pair_positions.pop(pair_key, None)
        
        df.iloc[i, df.columns.get_loc('Total_PnL')] = daily_pnl
        df.iloc[i, df.columns.get_loc('Cumulative_PnL')] = daily_pnl if i == 0 else df.iloc[i - 1]['Cumulative_PnL'] + daily_pnl
    
    output_columns = [f'Pos_{tenor}' for tenor in tenors] + \
                     ['Borrowed'] + \
                     [f'PnL_{pair[0]}_{pair[1]}' for pair in pairs] + \
                     ['Total_PnL', 'Cumulative_PnL']
    
    return df[output_columns]

# Example usage
# df = pd.read_csv('your_data.csv')
# result = apply_trading_strategy(df, tenors, pairs, pair_stop_loss=-1_000, daily_stop_loss=-10_000)
# print(result)




















import pandas as pd
import itertools

# List of bond tenors based on provided columns
tenors = ['26', '30', '31', '32', '35', '36', '37', '40', '41']

# Generate all possible pairs
pairs = list(itertools.combinations(tenors, 2))

# Initialize columns
def initialize_columns(df, tenors, pairs):
    for tenor in tenors:
        df[f'Pos_{tenor}'] = 0.0
    df['Borrowed'] = 0.0
    for pair in pairs:
        pair_key = f"{pair[0]}_{pair[1]}"
        df[f'PnL_{pair_key}'] = 0.0
    df['Total_PnL'] = 0.0
    df['Cumulative_PnL'] = 0.0
    return df

# Trading strategy logic
def apply_trading_strategy(df, tenors, pairs):
    df = initialize_columns(df, tenors, pairs)
    
    position_state = {f"{pair[0]}_{pair[1]}": False for pair in pairs}
    entry_price = {}
    pair_positions = {}  # Track pair-specific positions
    running_pnl = {f"{pair[0]}_{pair[1]}": 0.0 for pair in pairs}
    
    for i in range(len(df)):
        row = df.iloc[i]
        
        for pair in pairs:
            short_tenor, long_tenor = pair
            pair_key = f"{short_tenor}_{long_tenor}"
            z = row[(f'{short_tenor}_Yld', f'{long_tenor}_Yld')]
            
            if not position_state[pair_key]:
                if z >= 2:  # Spread too wide, expect it to narrow
                    # Short short_tenor, long long_tenor
                    scale = row[f'{long_tenor}_Dv01'] / row[f'{short_tenor}_Dv01']
                    notional = 1_000_000 / (row[f'{long_tenor}_Dv01'] + scale * row[f'{short_tenor}_Dv01'])
                    pos_short = -notional * scale
                    pos_long = notional
                    df.iloc[i, df.columns.get_loc(f'Pos_{short_tenor}')] += pos_short
                    df.iloc[i, df.columns.get_loc(f'Pos_{long_tenor}')] += pos_long
                    df.iloc[i, df.columns.get_loc('Borrowed')] += 1_000_000
                    entry_price[pair_key] = (row[f'{short_tenor}_Px'], row[f'{long_tenor}_Px'])
                    pair_positions[pair_key] = (pos_short, pos_long)
                    position_state[pair_key] = True
                    running_pnl[pair_key] = 0.0
                elif z <= -2:  # Spread too narrow, expect it to widen
                    # Long short_tenor, short long_tenor
                    scale = row[f'{long_tenor}_Dv01'] / row[f'{short_tenor}_Dv01']
                    notional = 1_000_000 / (row[f'{long_tenor}_Dv01'] + scale * row[f'{short_tenor}_Dv01'])
                    pos_short = notional * scale
                    pos_long = -notional
                    df.iloc[i, df.columns.get_loc(f'Pos_{short_tenor}')] += pos_short
                    df.iloc[i, df.columns.get_loc(f'Pos_{long_tenor}')] += pos_long
                    df.iloc[i, df.columns.get_loc('Borrowed')] += 1_000_000
                    entry_price[pair_key] = (row[f'{short_tenor}_Px'], row[f'{long_tenor}_Px'])
                    pair_positions[pair_key] = (pos_short, pos_long)
                    position_state[pair_key] = True
                    running_pnl[pair_key] = 0.0
            else:
                if i > 0:
                    current_price = (row[f'{short_tenor}_Px'], row[f'{long_tenor}_Px'])
                    pos_short, pos_long = pair_positions[pair_key]
                    unrealized_pnl = (current_price[0] - entry_price[pair_key][0]) * pos_short + \
                                     (current_price[1] - entry_price[pair_key][1]) * pos_long
                    running_pnl[pair_key] = unrealized_pnl
                
                if abs(z) <= 0.75 or running_pnl[pair_key] <= -1_000:
                    exit_price = (row[f'{short_tenor}_Px'], row[f'{long_tenor}_Px'])
                    pos_short, pos_long = pair_positions[pair_key]
                    pnl = (exit_price[0] - entry_price[pair_key][0]) * pos_short + \
                          (exit_price[1] - entry_price[pair_key][1]) * pos_long
                    df.iloc[i, df.columns.get_loc(f'PnL_{pair_key}')] = pnl
                    # Subtract this pair's positions
                    df.iloc[i, df.columns.get_loc(f'Pos_{short_tenor}')] -= pos_short
                    df.iloc[i, df.columns.get_loc(f'Pos_{long_tenor}')] -= pos_long
                    position_state[pair_key] = False
                    running_pnl[pair_key] = 0.0
                    pair_positions.pop(pair_key, None)
        
        total_pnl = sum(df.iloc[i][f'PnL_{pair[0]}_{pair[1]}'] for pair in pairs)
        df.iloc[i, df.columns.get_loc('Total_PnL')] = total_pnl
        df.iloc[i, df.columns.get_loc('Cumulative_PnL')] = total_pnl if i == 0 else df.iloc[i - 1]['Cumulative_PnL'] + total_pnl
    
    output_columns = [f'Pos_{tenor}' for tenor in tenors] + \
                     ['Borrowed'] + \
                     [f'PnL_{pair[0]}_{pair[1]}' for pair in pairs] + \
                     ['Total_PnL', 'Cumulative_PnL']
    
    return df[output_columns]

# Example usage
# df = pd.read_csv('your_data.csv')
# result = apply_trading_strategy(df, tenors, pairs)
# print(result)













import pandas as pd
import itertools

# List of bond tenors based on provided columns
tenors = ['26', '30', '31', '32', '35', '36', '37', '40', '41']

# Generate all possible pairs
pairs = list(itertools.combinations(tenors, 2))

# Initialize columns
def initialize_columns(df, tenors, pairs):
    # Position columns for each bond
    for tenor in tenors:
        df[f'Pos_{tenor}'] = 0.0
    
    # Borrowed amount column
    df['Borrowed'] = 0.0
    
    # PnL columns for each pair
    for pair in pairs:
        pair_key = f"{pair[0]}_{pair[1]}"
        df[f'PnL_{pair_key}'] = 0.0
    
    # Total and Cumulative PnL
    df['Total_PnL'] = 0.0
    df['Cumulative_PnL'] = 0.0
    
    return df

# Trading strategy logic
def apply_trading_strategy(df, tenors, pairs):
    df = initialize_columns(df, tenors, pairs)
    
    # Initialize position state and entry data for each pair
    position_state = {f"{pair[0]}_{pair[1]}": False for pair in pairs}
    entry_price = {}
    scale_factor = {}
    
    for i in range(len(df)):
        row = df.iloc[i]
        
        # Process each pair
        for pair in pairs:
            short_tenor, long_tenor = pair
            pair_key = f"{short_tenor}_{long_tenor}"
            
            # Calculate z-score for the pair
            z = row[(f'{short_tenor}_Yld', f'{long_tenor}_Yld')]
            
            if not position_state[pair_key]:
                # Entry logic
                if z > 2:
                    # Long short_tenor, short long_tenor
                    scale = row[f'{long_tenor}_Dv01'] / row[f'{short_tenor}_Dv01']
                    notional = 1_000_000 / (row[f'{long_tenor}_Dv01'] + scale * row[f'{short_tenor}_Dv01'])
                    df.iloc[i, df.columns.get_loc(f'Pos_{short_tenor}')] += notional * scale
                    df.iloc[i, df.columns.get_loc(f'Pos_{long_tenor}')] += -notional
                    df.iloc[i, df.columns.get_loc('Borrowed')] += 1_000_000
                    entry_price[pair_key] = (row[f'{short_tenor}_Px'], row[f'{long_tenor}_Px'])
                    scale_factor[pair_key] = scale
                    position_state[pair_key] = True
                elif z < -2:
                    # Short short_tenor, long long_tenor
                    scale = row[f'{long_tenor}_Dv01'] / row[f'{short_tenor}_Dv01']
                    notional = 1_000_000 / (row[f'{long_tenor}_Dv01'] + scale * row[f'{short_tenor}_Dv01'])
                    df.iloc[i, df.columns.get_loc(f'Pos_{short_tenor}')] += -notional * scale
                    df.iloc[i, df.columns.get_loc(f'Pos_{long_tenor}')] += notional
                    df.iloc[i, df.columns.get_loc('Borrowed')] += 1_000_000
                    entry_price[pair_key] = (row[f'{short_tenor}_Px'], row[f'{long_tenor}_Px'])
                    scale_factor[pair_key] = scale
                    position_state[pair_key] = True
            else:
                # Exit logic
                if abs(z) <= 0.75:
                    exit_price = (row[f'{short_tenor}_Px'], row[f'{long_tenor}_Px'])
                    # Calculate PnL
                    prev_pos_short = df.iloc[i - 1][f'Pos_{short_tenor}']
                    prev_pos_long = df.iloc[i - 1][f'Pos_{long_tenor}']
                    pnl = (exit_price[0] - entry_price[pair_key][0]) * prev_pos_short + \
                          (exit_price[1] - entry_price[pair_key][1]) * prev_pos_long
                    df.iloc[i, df.columns.get_loc(f'PnL_{pair_key}')] = pnl
                    position_state[pair_key] = False
        
        # Calculate Total PnL for the row
        total_pnl = sum(df.iloc[i][f'PnL_{pair[0]}_{pair[1]}'] for pair in pairs)
        df.iloc[i, df.columns.get_loc('Total_PnL')] = total_pnl
        
        # Calculate Cumulative PnL
        if i == 0:
            df.iloc[i, df.columns.get_loc('Cumulative_PnL')] = total_pnl
        else:
            df.iloc[i, df.columns.get_loc('Cumulative_PnL')] = df.iloc[i - 1]['Cumulative_PnL'] + total_pnl
    
    # Select relevant columns for output
    output_columns = [f'Pos_{tenor}' for tenor in tenors] + \
                     ['Borrowed'] + \
                     [f'PnL_{pair[0]}_{pair[1]}' for pair in pairs] + \
                     ['Total_PnL', 'Cumulative_PnL']
    
    return df[output_columns]

# Example usage
# df = pd.read_csv('your_data.csv')  # Load your data
# result = apply_trading_strategy(df, tenors, pairs)
# print(result)











# Initialize columns
df['Pos_26'] = 0.0
df['Pos_30'] = 0.0
df['Pos_35'] = 0.0
df['Borrowed'] = 0.0
df['PnL_26_30'] = 0.0
df['PnL_30_35'] = 0.0

# Strategy Logic
position_state = {'26_30': False, '30_35': False}
entry_price = {}
entry_dv01 = {}
scale_factor = {}

for i in range(len(df)):
    row = df.iloc[i]

    ### --- Spread 26Y-30Y ---
    z = row[('26_Yld', '30_Yld')]
    if not position_state['26_30']:
        if z > 2:
            scale = row['30_DV01'] / row['26_DV01']
            notional = 1_000_000 / (row['30_DV01'] + scale * row['26_DV01'])
            df.iloc[i, df.columns.get_loc('Pos_26')] = notional * scale
            df.iloc[i, df.columns.get_loc('Pos_30')] = -notional
            df.iloc[i, df.columns.get_loc('Borrowed')] = 1_000_000
            entry_price['26_30'] = (row['26_PX'], row['30_PX'])
            position_state['26_30'] = True
        elif z < -2:
            scale = row['30_DV01'] / row['26_DV01']
            notional = 1_000_000 / (row['30_DV01'] + scale * row['26_DV01'])
            df.iloc[i, df.columns.get_loc('Pos_26')] = -notional * scale
            df.iloc[i, df.columns.get_loc('Pos_30')] = notional
            df.iloc[i, df.columns.get_loc('Borrowed')] = 1_000_000
            entry_price['26_30'] = (row['26_PX'], row['30_PX'])
            position_state['26_30'] = True
    else:
        if abs(z) <= 0.75:
            exit_price = (row['26_PX'], row['30_PX'])
            pnl = (exit_price[0] - entry_price['26_30'][0]) * df.iloc[i - 1]['Pos_26'] + \
                  (exit_price[1] - entry_price['26_30'][1]) * df.iloc[i - 1]['Pos_30']
            df.iloc[i, df.columns.get_loc('PnL_26_30')] = pnl
            position_state['26_30'] = False

    ### --- Spread 30Y-35Y ---
    z = row[('30_Yld', '35_Yld')]
    if not position_state['30_35']:
        if z > 2:
            scale = row['35_DV01'] / row['30_DV01']
            notional = 1_000_000 / (row['35_DV01'] + scale * row['30_DV01'])
            df.iloc[i, df.columns.get_loc('Pos_30')] += notional * scale
            df.iloc[i, df.columns.get_loc('Pos_35')] = -notional
            df.iloc[i, df.columns.get_loc('Borrowed')] += 1_000_000
            entry_price['30_35'] = (row['30_PX'], row['35_PX'])
            position_state['30_35'] = True
        elif z < -2:
            scale = row['35_DV01'] / row['30_DV01']
            notional = 1_000_000 / (row['35_DV01'] + scale * row['30_DV01'])
            df.iloc[i, df.columns.get_loc('Pos_30')] += -notional * scale
            df.iloc[i, df.columns.get_loc('Pos_35')] = notional
            df.iloc[i, df.columns.get_loc('Borrowed')] += 1_000_000
            entry_price['30_35'] = (row['30_PX'], row['35_PX'])
            position_state['30_35'] = True
    else:
        if abs(z) <= 0.75:
            exit_price = (row['30_PX'], row['35_PX'])
            prev_pos30 = df.iloc[i - 1]['Pos_30'] - df.iloc[i - 1]['Pos_26']
            pnl = (exit_price[0] - entry_price['30_35'][0]) * prev_pos30 + \
                  (exit_price[1] - entry_price['30_35'][1]) * df.iloc[i - 1]['Pos_35']
            df.iloc[i, df.columns.get_loc('PnL_30_35')] = pnl
            position_state['30_35'] = False

# Total PnL
df['Total_PnL'] = df['PnL_26_30'] + df['PnL_30_35']
df[['Pos_26', 'Pos_30', 'Pos_35', 'Borrowed', 'PnL_26_30', 'PnL_30_35', 'Total_PnL']]









def plot_z_score_matrix(df, results, target_date, days_before=200, days_after=200, mpc_dates=None):
    target_date = pd.to_datetime(target_date)
    df_window = df[(df['Dates'] >= target_date - pd.Timedelta(days=days_before)) &
                   (df['Dates'] <= target_date + pd.Timedelta(days=days_after))]

    all_pairs = list(results.keys())
    short_tenors = sorted(set([p[0] for p in all_pairs]), key=lambda x: int(x.replace('Y', '')))
    long_tenors = sorted(set([p[1] for p in all_pairs]), key=lambda x: int(x.replace('Y', '')))

    fig, axes = plt.subplots(len(short_tenors), len(long_tenors), figsize=(len(long_tenors)*3, len(short_tenors)*2.5), sharex=True, sharey=True)
    
    for i, short in enumerate(short_tenors):
        for j, long in enumerate(long_tenors):
            ax = axes[i, j]

            if (short, long) in results:
                z = results[(short, long)].loc[df_window.index]
                ax.plot(df_window['Dates'], z, label=f"{short}-{long}", color='darkblue', linewidth=1)
                ax.axhline(0, color='black', linestyle='--', linewidth=0.8)
                ax.axhline(1, color='green', linestyle='--', linewidth=0.8)
                ax.axhline(-1, color='red', linestyle='--', linewidth=0.8)
                
                # MPC vertical lines
                if mpc_dates is not None:
                    for d in mpc_dates:
                        if df_window['Dates'].min() <= d <= df_window['Dates'].max():
                            ax.axvline(pd.to_datetime(d), color='purple', linestyle=':', linewidth=1)

            else:
                ax.axis('off')  # hide invalid combinations

            if i == len(short_tenors) - 1:
                ax.set_xlabel(long)
            if j == 0:
                ax.set_ylabel(short)

    plt.suptitle(f"Z-Score Spreads Around {target_date.strftime('%Y-%m-%d')}", fontsize=16)
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    plt.xticks(rotation=45)
    plt.show()




plot_z_score_matrix(df, results=results, target_date="2023-09-23", days_before=200, days_after=200, mpc_dates=mpc_dates)










import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv("Bond_Yield.csv", index_col="Dates")

# Get all yield columns
yield_columns = df.columns

# Generate all possible pairs
pairs = [(col1, col2) for i, col1 in enumerate(yield_columns) for col2 in yield_columns[i+1:]]

# Function to calculate Z-score
def calculate_z_score(series, window=10):
    rolling_mean = series.rolling(window=window).mean()
    rolling_std = series.rolling(window=window).std()
    z_score = (series - rolling_mean) / rolling_std
    return z_score

# Calculate spreads and Z-scores for each pair
results = {}
for pair in pairs:
    spread = df[pair[1]] - df[pair[0]]  # Longer maturity - shorter maturity
    z_score = calculate_z_score(spread)
    results[pair] = z_score

import math
import matplotlib.pyplot as plt
import pandas as pd

def plot_z_score_grid(df, results, target_date, days_before=200, days_after=200, mpc_dates=None):
    target_date = pd.to_datetime(target_date)

    # Slice data
    df_window = df[(df['Dates'] >= target_date - pd.Timedelta(days=days_before)) &
                   (df['Dates'] <= target_date + pd.Timedelta(days=days_after))]

    zscore_keys = list(results.keys())
    n_pairs = len(zscore_keys)

    # Define layout
    n_cols = 6
    n_rows = math.ceil(n_pairs / n_cols)
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 3), sharex=True)
    axes = axes.flatten()

    for pair_idx, pair in enumerate(zscore_keys):
        z_score = results[pair].loc[df_window.index]
        axes[pair_idx].plot(df_window['Dates'], z_score, label=f"{pair[0]}–{pair[1]}", color='darkblue')
        axes[pair_idx].axhline(0, color='black', linestyle='--', linewidth=1)
        axes[pair_idx].axhline(1, color='green', linestyle='--', linewidth=1, label='+1 std')
        axes[pair_idx].axhline(-1, color='red', linestyle='--', linewidth=1, label='-1 std')
        axes[pair_idx].set_title(f"{pair[0]}–{pair[1]}")
        axes[pair_idx].legend(fontsize=8)

        # MPC Dates
        if mpc_dates is not None and len(mpc_dates) > 0:
            for d in mpc_dates:
                if df_window['Dates'].min() <= d <= df_window['Dates'].max():
                    axes[pair_idx].axvline(pd.to_datetime(d), color='purple', linestyle=':', linewidth=1)

    # Hide unused axes
    for ax in axes[n_pairs:]:
        ax.axis('off')

    plt.tight_layout()
    plt.xticks(rotation=45)
    plt.show()

# Example usage (replace mpc_dates with your actual list)
plot_z_score_grid(df, target_date="2023-11-23", days_before=200, days_after=200, mpc_dates=mpc_dates)







# Step 1: compute window-based stats dynamically
window_stats_df = compute_spread_stats_window(df, target_date="2023-11-23", days_before=200, days_after=200)

# Step 2: Convert to dict for easy access
spread_stats = {
    tenor.replace("Spread_", "").replace("M", ""): {
        "median": window_stats_df.loc[tenor, 'median'],
        "std": window_stats_df.loc[tenor, 'std_dev']
    }
    for tenor in window_stats_df.index
}


# Step 3: Calculate pricing score columns
for m in range(1, 7):
    cb_col = f'CB_Zero_Spot_{m}M'
    ois_col = f'{m}M'
    spread_info = spread_stats[str(m)]
    
    fair_val = df[cb_col] + spread_info['median']
    score = (df[ois_col] - fair_val) / spread_info['std']
    df[f'Pricing_Score_{m}M'] = score


# -------------------------------------
# STEP 3: Plot Pricing Score Grid
# -------------------------------------
def plot_pricing_score_grid(df, target_date, days_before=200, days_after=200):
    import matplotlib.pyplot as plt
    import seaborn as sns

    # Filter
    df['Dates'] = pd.to_datetime(df['Dates'])
    target_date = pd.to_datetime(target_date)
    df_window = df[(df['Dates'] >= target_date - pd.Timedelta(days=days_before)) & 
                   (df['Dates'] <= target_date + pd.Timedelta(days=days_after))]

    # Set up grid
    fig, axes = plt.subplots(3, 2, figsize=(16, 12), sharex=True)
    axes = axes.flatten()

    for idx, m in enumerate(range(1, 7)):
        col = f'Pricing_Score_{m}M'
        sns.lineplot(x='Dates', y=col, data=df_window, ax=axes[idx], label=f'{m}M Score', color='darkblue')
        axes[idx].axhline(0, color='black', linestyle='--', linewidth=1)
        axes[idx].axhline(1, color='green', linestyle='--', linewidth=1, label='+1 std')
        axes[idx].axhline(-1, color='red', linestyle='--', linewidth=1, label='-1 std')
        axes[idx].set_title(f'Pricing Score: {m}M')
        axes[idx].legend()

        # Plot MPC dates
        for d in mpc_dates:
            if df_window['Dates'].min() <= d <= df_window['Dates'].max():
                axes[idx].axvline(d, color='purple', linestyle=':', linewidth=1)

    plt.tight_layout()
    plt.show()


plot_pricing_score_grid(df, target_date="2023-11-23", days_before=200, days_after=200)










for m in range(1, 7):
    spread_col = f'Spread_{m}M'
    z_col = f'Rolling_Z_{m}M'
    MA_col = f'MA_{m}M'
    df[z_col] = (df[spread_col] - df[spread_col].rolling(window=60).mean()) / \
                df[spread_col].rolling(window=60).std()
    df[MA_col] = df[spread_col].rolling(window=60).mean()










for m in range(1, 7):
    df[f'Spread_{m}M'] = df[f'Fwd_OIS_after_{m}M'] - df[f'CB_Zero_Spot_{m}M']


spread_stats = {}

for m in range(1, 7):
    spread_col = f'Spread_{m}M'
    stats = df[spread_col].describe()
    stats['median'] = df[spread_col].median()
    stats['std_dev'] = df[spread_col].std()
    stats['skew'] = df[spread_col].skew()
    stats['kurtosis'] = df[spread_col].kurt()
    spread_stats[spread_col] = stats

# Convert to DataFrame for display
spread_stats_df = pd.DataFrame(spread_stats)
print(spread_stats_df.T)



import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style="whitegrid")

def plot_spread_grid(df, mpc_dates, target_date, days_before=200, days_after=200):
    df['Dates'] = pd.to_datetime(df['Dates'])
    target_date = pd.to_datetime(target_date)
    start = target_date - pd.Timedelta(days=days_before)
    end = target_date + pd.Timedelta(days=days_after)

    df_sub = df[(df['Dates'] >= start) & (df['Dates'] <= end)].copy()
    
    fig, axs = plt.subplots(3, 2, figsize=(15, 10), sharex=True)
    axs = axs.flatten()

    for idx, m in enumerate(range(1, 7)):
        col = f'Spread_{m}M'
        ax = axs[idx]
        z_col = f'Rolling_Z_{m}M'
        sns.lineplot(data=df_sub, x='Dates', y=col, ax=ax)
        sns.lineplot(data=df_sub, x='Dates', y='Spread_3M', label='Spread_3M')
        sns.lineplot(data=df_sub, x='Dates', y=z_col, label='60D MA')
        ax.set_title(f'Spread {m}M: OIS - CB_Zero')
        ax.axvline(target_date, color='black', linestyle='-', label='Target Date')

        for mpc_date in mpc_dates:
            if start <= mpc_date <= end:
                ax.axvline(mpc_date, color='red', linestyle='--', alpha=0.6)

        ax.legend()
        ax.grid(True)

    plt.tight_layout()
    plt.show()



plot_spread_grid(df, mpc_dates, target_date="2023-11-23")





from datetime import timedelta

def compute_spread_stats_window(df, target_date, days_before=200, days_after=200):
    df['Dates'] = pd.to_datetime(df['Dates'])
    target_date = pd.to_datetime(target_date)
    start = target_date - pd.Timedelta(days=days_before)
    end = target_date + pd.Timedelta(days=days_after)

    df_window = df[(df['Dates'] >= start) & (df['Dates'] <= end)].copy()

    spread_stats = {}
    for m in range(1, 7):
        spread_col = f'Spread_{m}M'
        series = df_window[spread_col].dropna()
        stats = series.describe()
        stats['median'] = series.median()
        stats['std_dev'] = series.std()
        stats['skew'] = series.skew()
        stats['kurtosis'] = series.kurt()
        spread_stats[spread_col] = stats

    return pd.DataFrame(spread_stats).T




stats_around_date = compute_spread_stats_window(df, target_date="2023-11-23", days_before=200, days_after=200)
print(stats_around_date)
