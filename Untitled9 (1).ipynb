{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Busu2sWNAIAm"
      },
      "outputs": [],
      "source": [
        "# ZAR OIS Curve Prediction from o/n rate and FX spot using Deep Learning\n",
        "\n",
        "# STEP 1: Load and Inspect Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Input, RepeatVector, TimeDistributed\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the data\n",
        "file_path = \"ZAR_OIS_curve_data.csv\"  # Replace with your actual file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Convert 'Dates' column to datetime\n",
        "df['Dates'] = pd.to_datetime(df['Dates'])\n",
        "df.set_index('Dates', inplace=True)\n",
        "\n",
        "# Drop NA rows\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# STEP 2: Estimate Implied Forward o/n Rate / Zero Curve\n",
        "# Simple continuous compounding assumption using OIS rates\n",
        "# Formula: f(t,T) = [(1 + r(T))^T / (1 + r(t))^t]^(1/(T-t)) - 1\n",
        "\n",
        "def implied_forward_rate(r_short, r_long, t_short, t_long):\n",
        "    return ((1 + r_long)**t_long / (1 + r_short)**t_short)**(1 / (t_long - t_short)) - 1\n",
        "\n",
        "# Convert tenors to year fractions\n",
        "tenor_map = {\"1m\": 1/12, \"2m\": 2/12, \"3m\": 3/12, \"4m\": 4/12, \"5m\": 5/12, \"6m\": 6/12,\n",
        "             \"7m\": 7/12, \"8m\": 8/12, \"9m\": 9/12, \"1y\": 1, \"2y\": 2, \"3y\": 3}\n",
        "\n",
        "df_forward = pd.DataFrame(index=df.index)\n",
        "for i, (t1, t2) in enumerate(zip(list(tenor_map)[:-1], list(tenor_map)[1:])):\n",
        "    r1 = df[t1]\n",
        "    r2 = df[t2]\n",
        "    t1_frac = tenor_map[t1]\n",
        "    t2_frac = tenor_map[t2]\n",
        "    df_forward[f\"fwd_{t1}_{t2}\"] = implied_forward_rate(r1, r2, t1_frac, t2_frac)\n",
        "\n",
        "# Use all implied forwards and macro as features\n",
        "feature_cols = df_forward.columns.tolist() + ['USDZAR']\n",
        "X = pd.concat([df_forward, df['USDZAR']], axis=1).dropna()\n",
        "y = df.loc[X.index, list(tenor_map.keys())]  # target OIS curve\n",
        "\n",
        "# Build sequences to model time momentum (e.g., 7-day window)\n",
        "SEQUENCE_LENGTH = 7\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "for i in range(SEQUENCE_LENGTH, len(X)):\n",
        "    X_seq.append(X.iloc[i - SEQUENCE_LENGTH:i].values)\n",
        "    y_seq.append(y.iloc[i].values)\n",
        "\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "# Train-test split\n",
        "train_size = int(len(X_seq) * 0.8)\n",
        "X_train, X_test = X_seq[:train_size], X_seq[train_size:]\n",
        "y_train, y_test = y_seq[:train_size], y_seq[train_size:]\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped).reshape(X_train.shape)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped).reshape(X_test.shape)\n",
        "\n",
        "# STEP 3: Deep Learning Model with LSTM for temporal and macro modeling\n",
        "model = Sequential([\n",
        "    LSTM(64, input_shape=(SEQUENCE_LENGTH, X_train_scaled.shape[2]), return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_train.shape[1])\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "early_stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "model.fit(X_train_scaled, y_train,\n",
        "          validation_split=0.2,\n",
        "          epochs=100,\n",
        "          batch_size=32,\n",
        "          callbacks=[early_stop],\n",
        "          verbose=1)\n",
        "\n",
        "# Predict and Evaluate\n",
        "dl_preds = model.predict(X_test_scaled)\n",
        "dl_mse = mean_squared_error(y_test, dl_preds)\n",
        "dl_r2 = r2_score(y_test, dl_preds)\n",
        "print(f\"Deep Learning - MSE: {dl_mse:.4f}, R2: {dl_r2:.4f}\")\n",
        "\n",
        "# STEP 4: Visualize One Tenor and One Full Curve\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test[:, 9], label='Actual 1y')\n",
        "plt.plot(dl_preds[:, 9], label='Predicted 1y', linestyle='--')\n",
        "plt.title(\"1y OIS Point Prediction\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "sample_idx = 50\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(list(tenor_map.keys()), y_test[sample_idx], marker='o', label='Actual')\n",
        "plt.plot(list(tenor_map.keys()), dl_preds[sample_idx], marker='x', label='Predicted')\n",
        "plt.title(\"Full OIS Curve Prediction (Sample Day)\")\n",
        "plt.ylabel(\"Rate (%)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}