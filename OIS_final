import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.decomposition import PCA

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

# Set seed for reproducibility
torch.manual_seed(42)
np.random.seed(42)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")





class YieldLSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.2):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, num_layers=2, dropout=dropout, bidirectional=True)
        self.fc = nn.Sequential(
            nn.Linear(hidden_dim * 2, 128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, output_dim)
        )
        self.dropout = dropout

    def forward(self, x):
        self.train()  # Always enable dropout (MC Dropout)
        out, _ = self.lstm(x)
        out = out[:, -1, :]
        return self.fc(out)





def create_sequences(df, input_cols, target_cols, window=7):
    X_seq, y_seq, D_seq = [], [], []
    for i in range(len(df) - window):
        X_seq.append(df[input_cols].iloc[i:i+window].values)
        y_seq.append(df[target_cols].iloc[i+window].values)
        D_seq.append(df['Dates'].iloc[i+window])
    return np.array(X_seq), np.array(y_seq), np.array(D_seq)





def train_model(model, train_loader, val_loader, optimizer, loss_fn, device, max_epochs=50, patience=5):
    train_losses, val_losses = [], []
    best_model, best_val_loss = None, float('inf')
    wait = 0

    for epoch in range(max_epochs):
        model.train()
        train_loss = 0
        for xb, yb in train_loader:
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            preds = model(xb)
            loss = loss_fn(preds, yb)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        train_losses.append(train_loss)

        model.eval()
        val_loss = 0
        with torch.no_grad():
            for xb, yb in val_loader:
                xb, yb = xb.to(device), yb.to(device)
                preds = model(xb)
                val_loss += loss_fn(preds, yb).item()
        val_losses.append(val_loss)

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model = model.state_dict()
            wait = 0
        else:
            wait += 1
            if wait >= patience:
                break

    model.load_state_dict(best_model)

    plt.plot(train_losses, label="Train Loss")
    plt.plot(val_losses, label="Val Loss")
    plt.title("Loss Curve")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.show()

    return model





def plot_predictions(dates, y_true, y_pred, tenors):
    for i, tenor in enumerate(tenors):
        plt.figure(figsize=(10, 4))
        plt.plot(dates, y_true[:, i], label='Actual')
        plt.plot(dates, y_pred[:, i], '--', label='Predicted')
        plt.title(f"Yield: {tenor}")
        plt.xlabel("Date")
        plt.ylabel("Yield")
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()






def plot_yield_curves(y_true, y_pred, tenors):
    for i in range(0, len(y_pred), max(1, len(y_pred)//5)):
        plt.plot(tenors, y_true[i], label=f"True {i}")
        plt.plot(tenors, y_pred[i], '--', label=f"Pred {i}")
    plt.title("Yield Curve Shapes")
    plt.xlabel("Tenor")
    plt.ylabel("Yield")
    plt.legend()
    plt.grid(True)
    plt.show()




# Load and prepare
df = pd.read_csv("OIS_SPOT_ZAR.csv")
df.columns = df.columns.str.strip()
df['Dates'] = pd.to_datetime(df['Dates'])
df = df.sort_values("Dates").dropna()

target_cols = ["1M", "2M", "3M", "4M", "5M", "6M", "7M", "8M", "9M", "1Y", "2Y", "3Y"]
input_cols = [col for col in df.columns if col not in target_cols + ['Dates']]

# Downcast to save memory
df[input_cols] = df[input_cols].apply(pd.to_numeric, downcast='float')
df[target_cols] = df[target_cols].apply(pd.to_numeric, downcast='float')

# Scaling
scaler_X = StandardScaler()
X_scaled = scaler_X.fit_transform(df[input_cols].values)

pca = PCA(n_components=0.97)
X_pca = pca.fit_transform(X_scaled)
pca_cols = [f"PC{i+1}" for i in range(X_pca.shape[1])]

scaler_y = MinMaxScaler()
y_scaled = scaler_y.fit_transform(df[target_cols].values)

# Recombine into new df
df_final = pd.concat([
    df[['Dates']].reset_index(drop=True),
    pd.DataFrame(X_pca, columns=pca_cols),
    pd.DataFrame(y_scaled, columns=target_cols)
], axis=1)

# Sequence generation
X_seq, y_seq, D_seq = create_sequences(df_final, pca_cols, target_cols, window=7)

# Split
split = int(0.8 * len(X_seq))
X_train, X_val = X_seq[:split], X_seq[split:]
y_train, y_val = y_seq[:split], y_seq[split:]
dates_val = D_seq[split:]

# Dataloaders
train_loader = DataLoader(TensorDataset(torch.tensor(X_train, dtype=torch.float32),
                                        torch.tensor(y_train, dtype=torch.float32)), batch_size=32, shuffle=True)

val_loader = DataLoader(TensorDataset(torch.tensor(X_val, dtype=torch.float32),
                                      torch.tensor(y_val, dtype=torch.float32)), batch_size=32)

# Model
model = YieldLSTM(input_dim=X_seq.shape[2], hidden_dim=64, output_dim=len(target_cols), dropout=0.2).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
loss_fn = nn.MSELoss()

# Train
model = train_model(model, train_loader, val_loader, optimizer, loss_fn, device)





model.eval()
with torch.no_grad():
    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)
    y_val_pred_scaled = model(X_val_tensor).cpu().numpy()

# Inverse scale
y_val_pred = scaler_y.inverse_transform(y_val_pred_scaled)
y_val_true = scaler_y.inverse_transform(y_val)

# Metrics
r2_val = r2_score(y_val_true, y_val_pred)
mse_val = mean_squared_error(y_val_true, y_val_pred)

print(f"Validation R²: {r2_val:.4f}")
print(f"Validation MSE: {mse_val:.6f}")

# Full-dataset evaluation
with torch.no_grad():
    X_all_tensor = torch.tensor(X_seq, dtype=torch.float32).to(device)
    y_all_pred_scaled = model(X_all_tensor).cpu().numpy()
y_all_pred = scaler_y.inverse_transform(y_all_pred_scaled)
y_all_true = scaler_y.inverse_transform(y_seq)

r2_full = r2_score(y_all_true, y_all_pred)
mse_full = mean_squared_error(y_all_true, y_all_pred)
print(f"Full R²: {r2_full:.4f}")
print(f"Full MSE: {mse_full:.6f}")





plot_predictions(dates_val, y_val_true, y_val_pred, target_cols)
plot_yield_curves(y_val_true, y_val_pred, target_cols)





def predict_with_uncertainty(model, input_tensor, scaler_y, n_samples=30, ci=0.95):
    model.eval()
    preds = []

    for _ in range(n_samples):
        with torch.no_grad():
            pred = model(input_tensor).cpu().numpy()
            preds.append(pred)

    preds = np.array(preds).squeeze()  # (n_samples, output_dim)
    mean_pred = preds.mean(axis=0)
    std_pred = preds.std(axis=0)
    
    # 95% CI ~ 1.96 * std
    lower = scaler_y.inverse_transform([mean_pred - 1.96 * std_pred])[0]
    upper = scaler_y.inverse_transform([mean_pred + 1.96 * std_pred])[0]
    mean = scaler_y.inverse_transform([mean_pred])[0]

    # Plot
    plt.plot(target_cols, mean, label='Prediction', marker='o')
    plt.fill_between(target_cols, lower, upper, alpha=0.3, label='95% CI')
    plt.title("Predicted Yield Curve with Uncertainty")
    plt.ylabel("Yield")
    plt.xlabel("Tenor")
    plt.grid(True)
    plt.legend()
    plt.show()

    return mean, lower, upper




# Example: last available input
sample_input = torch.tensor(X_seq[-1:], dtype=torch.float32).to(device)
predict_with_uncertainty(model, sample_input, scaler_y)
