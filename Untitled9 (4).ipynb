{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Busu2sWNAIAm"
      },
      "outputs": [],
      "source": [
        "# ZAR OIS Curve Prediction from o/n rate and FX spot using Deep Learning\n",
        "\n",
        "# STEP 1: Load and Inspect Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Load the data\n",
        "file_path = \"ZAR_OIS_curve_data.csv\"  # Replace with your actual file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Convert 'Dates' column to datetime\n",
        "df['Dates'] = pd.to_datetime(df['Dates'])\n",
        "df.set_index('Dates', inplace=True)\n",
        "\n",
        "# Drop NA rows\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# STEP 2: Compute interpolated 1-day forward rate after each short-term tenor (1mâ€“6m)\n",
        "tenor_map = {\"1m\": 30/365, \"2m\": 60/365, \"3m\": 90/365, \"4m\": 120/365, \"5m\": 150/365, \"6m\": 180/365,\n",
        "             \"7m\": 210/365, \"8m\": 240/365, \"9m\": 270/365, \"1y\": 365/365, \"2y\": 2, \"3y\": 3}\n",
        "\n",
        "def calc_1d_forward(df_row, tenors=tenor_map):\n",
        "    curve_x = [tenors[k] for k in tenors]\n",
        "    curve_y = [df_row[k] for k in tenors]\n",
        "    interpolator = interp1d(curve_x, curve_y, kind='cubic', fill_value='extrapolate')\n",
        "    one_day = 1 / 365\n",
        "    results = {}\n",
        "    for k in [\"1m\", \"2m\", \"3m\", \"4m\", \"5m\", \"6m\"]:\n",
        "        base = tenors[k]\n",
        "        r1 = interpolator(base)\n",
        "        r2 = interpolator(base + one_day)\n",
        "        fwd_rate = ((1 + r2)**(base + one_day) / (1 + r1)**base)**(1 / one_day) - 1\n",
        "        results[f\"fwd_1d_after_{k}\"] = fwd_rate\n",
        "    return pd.Series(results)\n",
        "\n",
        "fwd_features = df.apply(calc_1d_forward, axis=1)\n",
        "\n",
        "# Combine features\n",
        "X = pd.concat([fwd_features, df[['USDZAR', 'o/n interest rate']]], axis=1).dropna()\n",
        "y = df.loc[X.index, list(tenor_map.keys())]  # target OIS curve\n",
        "\n",
        "# Build sequences to model time momentum (e.g., 7-day window)\n",
        "SEQUENCE_LENGTH = 7\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "dates_seq = []\n",
        "for i in range(SEQUENCE_LENGTH, len(X)):\n",
        "    X_seq.append(X.iloc[i - SEQUENCE_LENGTH:i].values)\n",
        "    y_seq.append(y.iloc[i].values)\n",
        "    dates_seq.append(X.index[i])\n",
        "\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "dates_seq = np.array(dates_seq)\n",
        "\n",
        "# Train-test split\n",
        "train_size = int(len(X_seq) * 0.8)\n",
        "X_train, X_test = X_seq[:train_size], X_seq[train_size:]\n",
        "y_train, y_test = y_seq[:train_size], y_seq[train_size:]\n",
        "dates_test = dates_seq[train_size:]\n",
        "\n",
        "# Normalize features and targets separately\n",
        "feature_scaler = StandardScaler()\n",
        "target_scaler = MinMaxScaler()\n",
        "\n",
        "X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "X_train_scaled = feature_scaler.fit_transform(X_train_reshaped).reshape(X_train.shape)\n",
        "X_test_scaled = feature_scaler.transform(X_test_reshaped).reshape(X_test.shape)\n",
        "\n",
        "y_train_scaled = target_scaler.fit_transform(y_train)\n",
        "y_test_scaled = target_scaler.transform(y_test)\n",
        "\n",
        "# STEP 3: Deep Learning Model with LSTM + Checkpointing\n",
        "model = Sequential([\n",
        "    LSTM(128, input_shape=(SEQUENCE_LENGTH, X_train_scaled.shape[2]), return_sequences=False),\n",
        "    Dropout(0.4),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(y_train.shape[1])\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "checkpoint_cb = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "early_stop = EarlyStopping(patience=15, restore_best_weights=True)\n",
        "model.fit(X_train_scaled, y_train_scaled,\n",
        "          validation_split=0.2,\n",
        "          epochs=200,\n",
        "          batch_size=32,\n",
        "          callbacks=[early_stop, checkpoint_cb],\n",
        "          verbose=1)\n",
        "\n",
        "# Predict and Evaluate\n",
        "best_model = tf.keras.models.load_model('best_model.keras')\n",
        "dl_preds_scaled = best_model.predict(X_test_scaled)\n",
        "dl_preds = target_scaler.inverse_transform(dl_preds_scaled)\n",
        "\n",
        "dl_mse = mean_squared_error(y_test, dl_preds)\n",
        "dl_r2 = r2_score(y_test, dl_preds)\n",
        "print(f\"Deep Learning - MSE: {dl_mse:.4f}, R2: {dl_r2:.4f}\")\n",
        "\n",
        "# STEP 4: Visualize All Tenors with Spread\n",
        "tenors = list(tenor_map.keys())\n",
        "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(18, 12), sharex=True)\n",
        "axes = axes.flatten()\n",
        "for i, tenor in enumerate(tenors):\n",
        "    ax = axes[i]\n",
        "    ax.plot(dates_test, y_test[:, i], label='Actual')\n",
        "    ax.plot(dates_test, dl_preds[:, i], label='Predicted', linestyle='--')\n",
        "    ax.fill_between(dates_test, y_test[:, i], dl_preds[:, i], color='gray', alpha=0.3, label='Spread')\n",
        "    ax.set_title(f\"{tenor} Tenor\")\n",
        "    ax.legend()\n",
        "    ax.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# STEP 5: Visualize Inputs + Curve Output\n",
        "sample_idx = 100  # pick a random test sample index\n",
        "input_window = X_test[sample_idx]\n",
        "input_features = X.columns.tolist()\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "for i in range(input_window.shape[1]):\n",
        "    plt.plot(range(SEQUENCE_LENGTH), input_window[:, i], label=input_features[i])\n",
        "plt.title(\"Input Features over 7 Days\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(tenors, y_test[sample_idx], marker='o', label='Actual Curve')\n",
        "plt.plot(tenors, dl_preds[sample_idx], marker='x', linestyle='--', label='Predicted Curve')\n",
        "plt.title(\"Actual vs Predicted Full OIS Curve\")\n",
        "plt.ylabel(\"Rate (%)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# STEP 6: Prediction on New Input (user-defined array)\n",
        "def predict_from_inputs(custom_inputs):\n",
        "    # custom_inputs shape: (7 days, same features as X.columns)\n",
        "    custom_inputs_scaled = feature_scaler.transform(custom_inputs)\n",
        "    custom_inputs_scaled = custom_inputs_scaled.reshape(1, SEQUENCE_LENGTH, -1)\n",
        "    pred_scaled = best_model.predict(custom_inputs_scaled)\n",
        "    pred = target_scaler.inverse_transform(pred_scaled)[0]\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(tenors, pred, marker='x', linestyle='--', label='Predicted Curve')\n",
        "    plt.title(\"Predicted OIS Curve for Custom Input\")\n",
        "    plt.ylabel(\"Rate (%)\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return pred\n",
        "\n",
        "# Example usage:\n",
        "# custom_inputs = np.array([...])  # shape: (7, num_features)\n",
        "# predict_from_inputs(custom_inputs)\n"
      ]
    }
  ]
}