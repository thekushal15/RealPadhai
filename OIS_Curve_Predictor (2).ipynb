{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Busu2sWNAIAm"
      },
      "outputs": [],
      "source": [
        "# ZAR OIS Curve Prediction from o/n rate and FX spot using Deep Learning (AutoML Enhanced)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import optuna\n",
        "\n",
        "# STEP 1: Load and Inspect Data\n",
        "file_path = \"ZAR_OIS_curve_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "df['Dates'] = pd.to_datetime(df['Dates'])\n",
        "df.set_index('Dates', inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# STEP 2: Generate Features\n",
        "tenor_map = {\"1m\": 30/365, \"2m\": 60/365, \"3m\": 90/365, \"4m\": 120/365, \"5m\": 150/365, \"6m\": 180/365,\n",
        "             \"7m\": 210/365, \"8m\": 240/365, \"9m\": 270/365, \"1y\": 365/365, \"2y\": 2, \"3y\": 3}\n",
        "\n",
        "def calc_1d_forward(df_row, tenors=tenor_map):\n",
        "    curve_x = [tenors[k] for k in tenors]\n",
        "    curve_y = [df_row[k] for k in tenors]\n",
        "    interpolator = interp1d(curve_x, curve_y, kind='cubic', fill_value='extrapolate')\n",
        "    one_day = 1 / 365\n",
        "    results = {}\n",
        "    for k in [\"1m\", \"2m\", \"3m\", \"4m\", \"5m\", \"6m\"]:\n",
        "        base = tenors[k]\n",
        "        r1 = interpolator(base)\n",
        "        r2 = interpolator(base + one_day)\n",
        "        fwd_rate = ((1 + r2)**(base + one_day) / (1 + r1)**base)**(1 / one_day) - 1\n",
        "        results[f\"fwd_1d_after_{k}\"] = fwd_rate\n",
        "    return pd.Series(results)\n",
        "\n",
        "fwd_features = df.apply(calc_1d_forward, axis=1)\n",
        "X = pd.concat([fwd_features, df[['USDZAR', 'o/n interest rate']]], axis=1).dropna()\n",
        "y = df.loc[X.index, list(tenor_map.keys())]\n",
        "\n",
        "SEQUENCE_LENGTH = 7\n",
        "X_seq, y_seq, dates_seq = [], [], []\n",
        "for i in range(SEQUENCE_LENGTH, len(X)):\n",
        "    X_seq.append(X.iloc[i - SEQUENCE_LENGTH:i].values)\n",
        "    y_seq.append(y.iloc[i].values)\n",
        "    dates_seq.append(X.index[i])\n",
        "\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "dates_seq = np.array(dates_seq)\n",
        "\n",
        "train_size = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:train_size], X_seq[train_size:]\n",
        "y_train, y_test = y_seq[:train_size], y_seq[train_size:]\n",
        "dates_test = dates_seq[train_size:]\n",
        "\n",
        "feature_scaler = StandardScaler()\n",
        "target_scaler = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = feature_scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
        "X_test_scaled = feature_scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
        "y_train_scaled = target_scaler.fit_transform(y_train)\n",
        "y_test_scaled = target_scaler.transform(y_test)\n",
        "\n",
        "# STEP 3: PyTorch LSTM Model and Optuna Tuning\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        x = self.fc1(h_n[-1])\n",
        "        x = self.drop(torch.relu(x))\n",
        "        return self.out(x)\n",
        "\n",
        "def objective(trial):\n",
        "    hidden_dim = trial.suggest_int(\"hidden_dim\", 64, 256)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "\n",
        "    model = LSTMModel(X_train_scaled.shape[2], hidden_dim, y_train.shape[1], dropout).to('cpu')\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    X_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
        "    loader = DataLoader(TensorDataset(X_tensor, y_tensor), batch_size=32, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(20):\n",
        "        for xb, yb in loader:\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    X_val_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "    y_val_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
        "    with torch.no_grad():\n",
        "        val_preds = model(X_val_tensor).numpy()\n",
        "    val_preds = target_scaler.inverse_transform(val_preds)\n",
        "    y_true = y_test\n",
        "    r2 = r2_score(y_true, val_preds)\n",
        "    return -r2  # Optuna minimizes\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=25)\n",
        "\n",
        "print(\"Best trial:\", study.best_trial.params)\n",
        "\n",
        "# Retrain with best params\n",
        "best = study.best_trial.params\n",
        "final_model = LSTMModel(X_train_scaled.shape[2], best['hidden_dim'], y_train.shape[1], best['dropout'])\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(final_model.parameters(), lr=best['lr'])\n",
        "\n",
        "final_model.train()\n",
        "train_loader = DataLoader(TensorDataset(torch.tensor(X_train_scaled, dtype=torch.float32),\n",
        "                                        torch.tensor(y_train_scaled, dtype=torch.float32)),\n",
        "                          batch_size=32, shuffle=True)\n",
        "for epoch in range(40):\n",
        "    for xb, yb in train_loader:\n",
        "        pred = final_model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluate on full test set\n",
        "final_model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_scaled = final_model(torch.tensor(X_test_scaled, dtype=torch.float32)).numpy()\n",
        "preds = target_scaler.inverse_transform(pred_scaled)\n",
        "\n",
        "# Scores\n",
        "mse = mean_squared_error(y_test, preds)\n",
        "r2 = r2_score(y_test, preds)\n",
        "print(f\"Optuna-LSTM Test MSE: {mse:.4f}, R2: {r2:.4f}\")\n",
        "\n",
        "# STEP 4: Visualization - Actual vs Predicted for Test Set\n",
        "tenors = list(tenor_map.keys())\n",
        "plt.figure(figsize=(22, 6))\n",
        "for i, tenor in enumerate(tenors):\n",
        "    plt.plot(dates_test, y_test[:, i], label=f\"Actual {tenor}\", alpha=0.8)\n",
        "    plt.plot(dates_test, preds[:, i], linestyle='--', label=f\"Predicted {tenor}\", alpha=0.7)\n",
        "plt.legend(ncol=6)\n",
        "plt.title(\"Test Set: Actual vs Predicted OIS Curve\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# STEP 5: Evaluate Model on Entire Dataset\n",
        "X_all_seq, y_all_seq, dates_all = [], [], []\n",
        "for i in range(SEQUENCE_LENGTH, len(X)):\n",
        "    X_all_seq.append(X.iloc[i - SEQUENCE_LENGTH:i].values)\n",
        "    y_all_seq.append(y.iloc[i].values)\n",
        "    dates_all.append(X.index[i])\n",
        "X_all_seq = np.array(X_all_seq)\n",
        "y_all_seq = np.array(y_all_seq)\n",
        "X_all_scaled = feature_scaler.transform(X_all_seq.reshape(-1, X_all_seq.shape[-1])).reshape(X_all_seq.shape)\n",
        "\n",
        "final_model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_all_scaled = final_model(torch.tensor(X_all_scaled, dtype=torch.float32)).numpy()\n",
        "preds_all = target_scaler.inverse_transform(preds_all_scaled)\n",
        "\n",
        "# Full Dataset R2 and MSE\n",
        "full_mse = mean_squared_error(y_all_seq, preds_all)\n",
        "full_r2 = r2_score(y_all_seq, preds_all)\n",
        "print(f\"Full Dataset MSE: {full_mse:.4f}, R2: {full_r2:.4f}\")\n",
        "\n",
        "# STEP 6: Interactive Prediction\n",
        "def predict_yield_curve(custom_input):\n",
        "    input_df = pd.DataFrame([custom_input])\n",
        "    input_scaled = feature_scaler.transform(input_df.values)\n",
        "    input_seq = np.tile(input_scaled, (SEQUENCE_LENGTH, 1))\n",
        "    input_tensor = torch.tensor(input_seq[np.newaxis, :, :], dtype=torch.float32)\n",
        "    final_model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_scaled = final_model(input_tensor).numpy()\n",
        "    pred = target_scaler.inverse_transform(pred_scaled)\n",
        "    return pred.flatten()\n",
        "\n",
        "# Example usage\n",
        "example_input = {\n",
        "    'fwd_1d_after_1m': 0.072,\n",
        "    'fwd_1d_after_2m': 0.071,\n",
        "    'fwd_1d_after_3m': 0.070,\n",
        "    'fwd_1d_after_4m': 0.069,\n",
        "    'fwd_1d_after_5m': 0.068,\n",
        "    'fwd_1d_after_6m': 0.067,\n",
        "    'USDZAR': 18.2,\n",
        "    'o/n interest rate': 0.071\n",
        "}\n",
        "predicted_curve = predict_yield_curve(example_input)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(tenors, predicted_curve, marker='o')\n",
        "plt.title(\"Predicted ZAR OIS Curve from Custom Inputs\")\n",
        "plt.xlabel(\"Tenor\")\n",
        "plt.ylabel(\"Rate\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ZAR OIS Curve Prediction from o/n rate and FX spot using Deep Learning (AutoML Enhanced)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import optuna\n",
        "\n",
        "# STEP 1: Load and Inspect Data\n",
        "file_path = \"ZAR_OIS_curve_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "df['Dates'] = pd.to_datetime(df['Dates'])\n",
        "df.set_index('Dates', inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# STEP 2: Generate Features\n",
        "tenor_map = {\"1m\": 30/365, \"2m\": 60/365, \"3m\": 90/365, \"4m\": 120/365, \"5m\": 150/365, \"6m\": 180/365,\n",
        "             \"7m\": 210/365, \"8m\": 240/365, \"9m\": 270/365, \"1y\": 365/365, \"2y\": 2, \"3y\": 3}\n",
        "\n",
        "def calc_1d_forward(df_row, tenors=tenor_map):\n",
        "    curve_x = [tenors[k] for k in tenors]\n",
        "    curve_y = [df_row[k] for k in tenors]\n",
        "    interpolator = interp1d(curve_x, curve_y, kind='cubic', fill_value='extrapolate')\n",
        "    one_day = 1 / 365\n",
        "    results = {}\n",
        "    for k in [\"1m\", \"2m\", \"3m\", \"4m\", \"5m\", \"6m\"]:\n",
        "        base = tenors[k]\n",
        "        r1 = interpolator(base)\n",
        "        r2 = interpolator(base + one_day)\n",
        "        fwd_rate = ((1 + r2)**(base + one_day) / (1 + r1)**base)**(1 / one_day) - 1\n",
        "        results[f\"fwd_1d_after_{k}\"] = fwd_rate\n",
        "    return pd.Series(results)\n",
        "\n",
        "fwd_features = df.apply(calc_1d_forward, axis=1)\n",
        "X = pd.concat([fwd_features, df[['USDZAR', 'o/n interest rate']]], axis=1).dropna()\n",
        "y = df.loc[X.index, list(tenor_map.keys())]\n",
        "\n",
        "SEQUENCE_LENGTH = 7\n",
        "X_seq, y_seq, dates_seq = [], [], []\n",
        "for i in range(SEQUENCE_LENGTH, len(X)):\n",
        "    X_seq.append(X.iloc[i - SEQUENCE_LENGTH:i].values)\n",
        "    y_seq.append(y.iloc[i].values)\n",
        "    dates_seq.append(X.index[i])\n",
        "\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "dates_seq = np.array(dates_seq)\n",
        "\n",
        "train_size = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:train_size], X_seq[train_size:]\n",
        "y_train, y_test = y_seq[:train_size], y_seq[train_size:]\n",
        "dates_test = dates_seq[train_size:]\n",
        "\n",
        "feature_scaler = StandardScaler()\n",
        "target_scaler = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = feature_scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
        "X_test_scaled = feature_scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
        "y_train_scaled = target_scaler.fit_transform(y_train)\n",
        "y_test_scaled = target_scaler.transform(y_test)\n",
        "\n",
        "# STEP 3: PyTorch LSTM Model and Optuna Tuning\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        x = self.fc1(h_n[-1])\n",
        "        x = self.drop(torch.relu(x))\n",
        "        return self.out(x)\n",
        "\n",
        "def objective(trial):\n",
        "    hidden_dim = trial.suggest_int(\"hidden_dim\", 64, 256)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "\n",
        "    model = LSTMModel(X_train_scaled.shape[2], hidden_dim, y_train.shape[1], dropout).to('cpu')\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    X_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
        "    loader = DataLoader(TensorDataset(X_tensor, y_tensor), batch_size=32, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(20):\n",
        "        for xb, yb in loader:\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    X_val_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "    y_val_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
        "    with torch.no_grad():\n",
        "        val_preds = model(X_val_tensor).numpy()\n",
        "    val_preds = target_scaler.inverse_transform(val_preds)\n",
        "    y_true = y_test\n",
        "    r2 = r2_score(y_true, val_preds)\n",
        "    return -r2  # Optuna minimizes\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=25)\n",
        "\n",
        "print(\"Best trial:\", study.best_trial.params)\n",
        "\n",
        "# Retrain with best params\n",
        "best = study.best_trial.params\n",
        "final_model = LSTMModel(X_train_scaled.shape[2], best['hidden_dim'], y_train.shape[1], best['dropout'])\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(final_model.parameters(), lr=best['lr'])\n",
        "\n",
        "final_model.train()\n",
        "train_loader = DataLoader(TensorDataset(torch.tensor(X_train_scaled, dtype=torch.float32),\n",
        "                                        torch.tensor(y_train_scaled, dtype=torch.float32)),\n",
        "                          batch_size=32, shuffle=True)\n",
        "for epoch in range(40):\n",
        "    for xb, yb in train_loader:\n",
        "        pred = final_model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluate on full test set\n",
        "final_model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_scaled = final_model(torch.tensor(X_test_scaled, dtype=torch.float32)).numpy()\n",
        "preds = target_scaler.inverse_transform(pred_scaled)\n",
        "\n",
        "# Scores\n",
        "mse = mean_squared_error(y_test, preds)\n",
        "r2 = r2_score(y_test, preds)\n",
        "print(f\"Optuna-LSTM Test MSE: {mse:.4f}, R2: {r2:.4f}\")\n",
        "\n",
        "# STEP 4: Visualization - Actual vs Predicted for Test Set\n",
        "tenors = list(tenor_map.keys())\n",
        "plt.figure(figsize=(22, 6))\n",
        "for i, tenor in enumerate(tenors):\n",
        "    plt.plot(dates_test, y_test[:, i], label=f\"Actual {tenor}\", alpha=0.8)\n",
        "    plt.plot(dates_test, preds[:, i], linestyle='--', label=f\"Predicted {tenor}\", alpha=0.7)\n",
        "plt.legend(ncol=6)\n",
        "plt.title(\"Test Set: Actual vs Predicted OIS Curve\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# STEP 5: Evaluate Model on Entire Dataset\n",
        "X_all_seq, y_all_seq, dates_all = [], [], []\n",
        "for i in range(SEQUENCE_LENGTH, len(X)):\n",
        "    X_all_seq.append(X.iloc[i - SEQUENCE_LENGTH:i].values)\n",
        "    y_all_seq.append(y.iloc[i].values)\n",
        "    dates_all.append(X.index[i])\n",
        "X_all_seq = np.array(X_all_seq)\n",
        "y_all_seq = np.array(y_all_seq)\n",
        "X_all_scaled = feature_scaler.transform(X_all_seq.reshape(-1, X_all_seq.shape[-1])).reshape(X_all_seq.shape)\n",
        "\n",
        "final_model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_all_scaled = final_model(torch.tensor(X_all_scaled, dtype=torch.float32)).numpy()\n",
        "preds_all = target_scaler.inverse_transform(preds_all_scaled)\n",
        "\n",
        "# Full Dataset R2 and MSE\n",
        "full_mse = mean_squared_error(y_all_seq, preds_all)\n",
        "full_r2 = r2_score(y_all_seq, preds_all)\n",
        "print(f\"Full Dataset MSE: {full_mse:.4f}, R2: {full_r2:.4f}\")\n",
        "\n",
        "# STEP 6: Interactive Prediction with Confidence Interval\n",
        "def predict_yield_curve_with_ci(custom_input, n_simulations=50):\n",
        "    input_df = pd.DataFrame([custom_input])\n",
        "    input_scaled = feature_scaler.transform(input_df.values)\n",
        "    input_seq = np.tile(input_scaled, (SEQUENCE_LENGTH, 1))\n",
        "    input_tensor = torch.tensor(input_seq[np.newaxis, :, :], dtype=torch.float32)\n",
        "    final_model.eval()\n",
        "\n",
        "    preds = []\n",
        "    for _ in range(n_simulations):\n",
        "        with torch.no_grad():\n",
        "            pred_scaled = final_model(input_tensor).numpy()\n",
        "            pred = target_scaler.inverse_transform(pred_scaled).flatten()\n",
        "            preds.append(pred)\n",
        "    preds = np.array(preds)\n",
        "    mean_pred = preds.mean(axis=0)\n",
        "    lower_bound = np.percentile(preds, 2.5, axis=0)\n",
        "    upper_bound = np.percentile(preds, 97.5, axis=0)\n",
        "\n",
        "    return mean_pred, lower_bound, upper_bound\n",
        "\n",
        "# Example usage\n",
        "example_input = {\n",
        "    'fwd_1d_after_1m': 0.072,\n",
        "    'fwd_1d_after_2m': 0.071,\n",
        "    'fwd_1d_after_3m': 0.070,\n",
        "    'fwd_1d_after_4m': 0.069,\n",
        "    'fwd_1d_after_5m': 0.068,\n",
        "    'fwd_1d_after_6m': 0.067,\n",
        "    'USDZAR': 18.2,\n",
        "    'o/n interest rate': 0.071\n",
        "}\n",
        "mean_pred, lower, upper = predict_yield_curve_with_ci(example_input)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(tenors, mean_pred, marker='o', label='Mean Prediction')\n",
        "plt.fill_between(tenors, lower, upper, color='gray', alpha=0.3, label='95% Confidence Interval')\n",
        "plt.title(\"Predicted ZAR OIS Curve with 95% Confidence Interval\")\n",
        "plt.xlabel(\"Tenor\")\n",
        "plt.ylabel(\"Rate\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gXIQPXeFCA92"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}